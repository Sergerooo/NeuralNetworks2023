{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot  as plt\n",
    "\n",
    "# Device configuration\n",
    "device = 'cpu'#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Этап - подготовка данных!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Этап - Нейронная сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Lenet5.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class Lenet5(nn.Module):\n",
    "    def __init__(self, hidden_size1=500, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(20)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(50 * 4 * 4, hidden_size1) # fully connected\n",
    "        self.fc2 = nn.Linear(hidden_size1, num_classes)  \n",
    "    \n",
    "    def forward(self, x): # вход размера 1 x 28 x 28\n",
    "        out = self.conv1(x) # на выходе размер 20 x 24 x 24\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.maxpool(out) # на выходе размер 20 x 12 x 12\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # на выходе размер 50 x 8 x 8\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.maxpool(out) # на выходе размер 50 x 4 x 4\n",
    "        out = self.relu(out)\n",
    "        out = out.reshape(-1, 50 * 4 * 4) # на выходе размер 800\n",
    "        out = self.fc1(out) # на выходе размер 500\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out) # на выходе размер 10\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = Lenet5(hidden_size1=500, num_classes=10).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_block(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.fc(out)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        self.block = NN_block(input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(10):\n",
    "            out = self.block(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 этап - Loss-функция и оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1336,  0.1986,  0.1058, -0.0056, -0.1951],\n",
       "         [-0.0087,  0.1795, -0.0947,  0.1587, -0.1071],\n",
       "         [ 0.0484,  0.1796,  0.0676, -0.0872, -0.1053],\n",
       "         [ 0.1274,  0.0026,  0.1132,  0.0337,  0.0309],\n",
       "         [-0.0159,  0.0652,  0.0210, -0.1225, -0.1820]]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0903, -0.0053, -0.0760, -0.0431,  0.0639, -0.1037,  0.0474,  0.0758,\n",
       "         0.1286,  0.1351,  0.1329, -0.1138,  0.0712, -0.0653, -0.1147, -0.0645,\n",
       "         0.1803, -0.1606,  0.1681,  0.0211], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 этап - обучение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 28, 28]), torch.Size([100]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(train_loader):  \n",
    "    break\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1504\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1995\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1652\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0907\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0755\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0759\n",
      "Accuracy of the network on the 10000 test images: 98.49 %\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0134\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0809\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0315\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0262\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0125\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0315\n",
      "Accuracy of the network on the 10000 test images: 98.8 %\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0375\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0221\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0064\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0193\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0034\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0392\n",
      "Accuracy of the network on the 10000 test images: 98.71 %\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0150\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0180\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0626\n",
      "Epoch [4/5], Step [400/600], Loss: 0.1010\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0090\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0078\n",
      "Accuracy of the network on the 10000 test images: 99.11 %\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0041\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0475\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0059\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0020\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0237\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0118\n",
      "Accuracy of the network on the 10000 test images: 98.97 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    # Test the model\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            #images = images.reshape(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([20, 1, 5, 5]) 500\n",
      "conv1.bias torch.Size([20]) 20\n",
      "conv2.weight torch.Size([50, 20, 5, 5]) 25000\n",
      "conv2.bias torch.Size([50]) 50\n",
      "fc1.weight torch.Size([500, 800]) 400000\n",
      "fc1.bias torch.Size([500]) 500\n",
      "fc2.weight torch.Size([10, 500]) 5000\n",
      "fc2.bias torch.Size([10]) 10\n",
      "431080\n"
     ]
    }
   ],
   "source": [
    "ss = []\n",
    "for name, p in model.named_parameters():\n",
    "    ss.append(p.numel())\n",
    "    print(name, p.shape, p.numel())\n",
    "print(sum(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
